HA means Hack Assembly.
I'm using "you" to address myself.





April 11th, 2022

Unit 1.0
road map: Jack→Compiler→VM→Translator→assembly→assembler→computer



Unit 1.1

preview of end:
	review of jack
	get to high-level programs
	write once, run anywhere! as opposed to write once, fix everywhere
	java VM: bytecode, give computers JVM implementation
	vm translator!
	translating from one language to an assembly script is a headache
	use intermediate steps: one compiler, a couple translators, a couple assemblers
	idea is almost 90 years old!

preview of jack:
	java similarity
	one platform, PC, other Hack
	write compiler, put in Jack code, write translator, put in VM code

virtual machine:
	virtualization
	not real
	alan turing is very happy!
	reason about reasoning
	turing: "we can only see a short distance ahead, but we can see plenty there that needs to be done"

take home lessons:
	compilation
	virtualization
	VM abstraction
	stack processing
	VM implementation
	pointers
	programming



Unit 1.2

two conflicting objectives: height, lowness
jump should not be very high

optimal jump: stack machine abstraction
	architecture (stack):
		operations are push and pop
		stack is similar to ram (memory)
		memory = array, stack = stack
		push memory: add to stack
		pop memory: remove from stack, add to memory
	arithmetic commands:
		add: pop two topmost values, add on side, push result
		neg: pop top value, negate side, push back on
		function: pop arguments, compute f, push result (part of abstraction)
		eq: pop two top values, check if equal, push result back on
		or: pop two top values, evaluate boolean or, push result on



Unit 1.2, second and third session

two conflicting objectives: height, lowness
jump should not be very high

optimal jump: stack
	architecture (stack):
		operations are push and pop
		stack is similar to ram (memory)
		memory = array, stack = stack
		push memory: add to stack
		pop memory: remove from stack, add to memory
	
	arithmetic commands:
		add: pop two topmost values, add on side, push result
		neg: pop top value, negate side, push back on
		function: pop arguments, compute f, push result (part of abstraction)
		eq: pop two top values, check if equal, push result back on
		or: pop two top values, evaluate boolean or, push result on
	
	where did these commands come from?
		the compiler!
		start from x = 17 + 19
		compile: push 17; push 19; add; pop x
		the high-level language is an abstraction
		it can be implemented by a stack machine
		the stack machine is an abstraction
		it can be implemented by something unknown
	
	VM code is a stack machine manipulated by:
		arithmetic / logical commands → example
		memory segment commands
		branching commands
		function commands

	arithmetic/logical commands are:
		add			x + y
		sub			x - y
		neg			-y
		eq			x == 0 (error? this should be x==y)
		gt			x > y
		lt			x < y
		and			x and y
		or 			x or y
		not			not y

	observation:
		any expression that is arithmetic or logical can be evaluated with this stack.
		You can do anything with VM codes. Tigress out.



Unit 1.3, number of sessions: 2

let c = s1 + y; → compiler → push s1; push y; add; pop c
how did compiler do this?





April 13th

Unit 1.3, number of sessions today: 1

[0250]-	cannot preserve variable names or else execution will be wrong
introducing: virtual memory segments!

instead of saying `push s1` we say `push ${s1Value}` but we lose variable names

jvm does not interpret symbolic variable names.

memory segment: constant! just 0-1-2-3-4-5-...

why do we always have to say ... segment ...?
	because it needs to be consistent and easy to compile

actually there are eight memory segments, not four! why though?
	we come from object oriented programs
	there are a lot of variables and nuances there
	for example, we always reference a lot of numbers

there is one thing that eight memory segments versus one does not affect:
	all push statements are the same!

[0258]-	quiz

imprint a value: quiz
solution:
	push imprint
	pop imprinted
THE only way is this!

finished talking about:
	arithmetic/logical commands (pseudo-quiz up ahead for me!)
	memory segment commands (push segment i, pop nonConstantSegment i)

arithmetic/logical commands:
	add
	sub
	neg
	eq
	gt
	lt
	and
	or
	not



Unit 1.4

[0315]-	everything seen is imaginary!

we need to make an imaginary machine real. What to do?
	first, we need to map every segment on the RAM (and remember it)

crash course on pointer

time to get into pseudo-assembly (soda assembly)

D = *p (what does that mean?)

*p is memory location that p points at
	check value at ram0
	look at value at ram0 value address
	in hack:
	@p
	A=M
	D=M

what does p-- mean? now D=*p
	in hack:
	@p
	M=M-1
	A=M
	D=M

[0406]-	new script!
	*q = 9
	q++

[0817]-	how do we represent this in Hack?
	SP=0
	stack base address = 256

another new script!
*SP = 17
SP++

implementation:
	@17 // D=17
	D=A
	@SP // *SP=D
	A=M
	M=D
	@SP // SP++
	M=M+1

[0835]-	previous Hack code is implementation for push when i replaces 17

VM translator: receive stream of commands, spit out normal assembly
Perhaps a good intermediate step would be to spit out pseudo assembly



Unit 1.5

[1119]-	start with stack, 8 abstract memory segments

push/pop segment i is the syntax for every memory segment

...well... except for the constant memory segment

examples:
	push constant 17
	pop local 2
	pop static 5
	push argument 3
	pop this 2

implementation:
	we have an abstraction
	we have a Hack RAM
	SP (stack top)
	we see LCL
	stack starts at 256
	local starts at 1015?

notice: anything two below SP is kaput (dead)
can be recycled at will

implementation for push constant i
	@17 // D=17
	D=A
	@SP // *SP=D
	A=M
	M=D
	@SP // SP++
	M=M+1

implementation for pop local i
	@i		# load i
	D=A		# assign i to D register
	@LCL	# load LCL=1, value 1015
	D=M+D	# D = RAM[LCL]+i = RAM[1]+i = 1015+2 = 1017, turn into RAM[1017]

	@SP		# load SP
	M=M-1	# decrement SP to 257
	A=M		# goto RAM[257]
	D=M		# store RAM[257]... but we can no longer put it into where LCL is
	# This doesn't work anymore because I need 2 D registers but I only have one.

2nd implementation for pop local i
	@i		# load i
	D=A		# assign i to D register
	@LCL	# load LCL=1, value 1015
	D=M+D	# D = RAM[LCL]+i = RAM[1]+i = 1015+2 = 1017, turn into RAM[1017]
	@R13	# create temporary variable addr
	M=D		# set addr's memory value to 1017

	@SP		# load SP
	M=M-1	# decrement SP to 257
	A=M		# goto RAM[257]
	D=M		# store RAM[257]

	@R13	# goto addr
	A=M		# get RAM[1017]
	M=D		# RAM[1017]=RAM[257]
	# Note: There's no cleanup required because the new value at SP will be overwritten.

what I need to do:
first, calculate what the address at LCL + i is
then I need to decrement SP
finally I need to set wherever the address is to wherever SP is

four memory segments together:
	local, argument - local variables in function, arguments of function
	this, that - object fields, array entries
	abstractly, used the same way!
	implemented in the same way!

pseudo-assembly code for segments:
	addr = segmentPointer + i, *SP = *addr, SP++
	addr = segmentPointer + i, SP--, *addr = *SP

common question: where are the four memory segments located?
	answer: it's handled by the OS

next memory segment is constant:
	compiler often encounters constants and has to translate them into a constant segment.
	commands:
		only push constant i. there's no pop constant i operation - that wouldn't make sense.
	implementation of commands:
		push constant i: *SP = i, SP++
		@i		# i = 2 in this example
		D=A		# D = 2
		@SP		# SP = 256 in this example
		A=M		# A = 256, RAM[256] is selected
		M=D		# M = I
		@SP		# SP = 256
		M=M+1	# SP++

[1400]- Implementing static variables

Static variables should be seen by everyone

Solution: store them in a global space!
	We need a VM reference "static i" in the file Foo.vm turned into an assembly reference called Foo.i.

create variable @Foo.5 at the end and store the variable locally

static variables will be mapped to RAM[16] through RAM[255] (in case you need so many!)

there is one weird convention: there is no variable sorting so order matters!

previously, Shimon has said nothing about the underlying platform (other than the stack)
now, we are dealing with the fact that everything is based on one platform for everyone to access.

temp is a fixed 8-place memory segment going from RAM[5..12]
leaves 3 extra variables to use: R13, R14, and R15.
Base address: 5





April 14th, 2022

[Still on Unit 1.5]

[1041]
pointer is a fixed two-place segment:
	push pointer 0/1
	pop pointer 0/1

accessing pointer 0: accessing THIS
accessing pointer 1: accessing THAT

funny joke: "with THIS in mind, or with THAT in mind, as you please"

implementation for push pointer 0/1
	@THIS/THAT	# we use whatever is dictated
	D=M			# D = value of THIS/THAT
	@SP			# SP = 256 in this example
	A=M			# A = 256, RAM[256] is selected
	M=D			# M = I
	@SP			# SP = 256
	M=M+1		# SP++

Arithmetic / Logical commands
	add
	sub
	neg
	eq
	get?? where did THAT come from? (actually it's a typo for gt)
	lt
	and
	or
	not

Memory access commands
	pop segment i
	push segment i

	(now, for constant, there is no pop)

we don't need to handle branching and function commands yet



Unit 1.6

[1120]-	The VM emulator gets VM code to run on your PC, not just the Hack computer.

It's helpful for a number of reasons:
	Typical uses:
		Running compiled Jack programs
		Testing programs systematically
		Experimenting with VM commands
		Observing the VM internals like the stack and memory segments (20² lines now!)
		Observing how the VM is realized on the host platform
	
	Personal uses:
		Tinkering with the program
		Waiting for some bouncy ball on the screen (that never comes)
		Pondering Jack code
		Looking at code without comments and whitespace

The VM emulator's multi-purpose pane allows you to view:
	Program output
	Test script
	Output file
	Compare file

Test scripts take Name.vm and have NameVME.tst.

if the VM translator passes all the tests, it signals the end of your learning.
otherwise, it raises a nice red error with lines you need to fix.

I'm being so negative about passing tests because it means you can't learn more.
On the other hand, when you get an error, it's nice because you can learn more now!

There's no need to delve into the code of test scripts
	...but who cares about what you "need", gimme the learning opportunities now!

missing elements:
	sequences of instructions are VM files without the function-return envelope
	you need to take care of initializations

next: VM emulator demo!
	fast forward: single step collection

recap:
	the VM emulator helps us:
		Run and test high-level programs
		Understand the VM
			abstraction
			implementation



Unit 1.7

[1316]

CAPS-LOCK
VM translator review
	CONVENTION: Write comment for what line you are translating!

Prerequisites for VM translator:
	Understand VM
	Understand HA
	Understand mapping between VM and HA

Source: VM
	Composed of two fields: arithmetic/logical commands and memory access commands.
	Arithmetic/Logical commands:
		add
		sub
		neg
		eq
		gt
		lt
		and
		or
		not
	Memory access commands:
		pop segment i
		push segment i

	(technically VM also has branching and function commands, but that's project 8, not 7)





April 15th, 2022

[Still on Unit 1.7]

Target: HA
	C-instructions
	A-instructions
	and that is it. very simple language.

Standard VM mapping:
	VM mapping decisions:
		How to map the VM's data structures using the host hardware platform
		How to exprses the VM's commands using the host machine language

	Standard mapping:
		Specifies how to do the mapping in an agreed-upon way
		Benefits:
			Compatibility with other software systems
			Standard testing

The standard mapping gives:
	5 stack pointers
	temp segment
	3 general perpose registers
	static variables
	a giant stack



Unit 1.8

The VM translator: usage
	take myProg.vm
	run java VMTranslator myProg.vm (depends on language and machine)
	myProg.asm will be created
	use Sublime Text(?) to open myProg.asm

Proposed design:
	Parser:		parses each VM command into its lexical elements
	CodeWriter:	writes the assembly code that implements the parsed commands
	Main:		drives the process (VMTranslator)

	Main (VMTranslator)
	Input: fileName.vm
	Output: fileName.asm

	Main logic:
		Constructs a Parser to handle input file
		Constructs a CodeWriter to handle the output file
		Marches through the input file, parsing each line and generating code from it.

You need to know how to parse files before starting!
If you don't know you should probably go look it up.

The parser:
	Handles the parsing of a single .vm file,
	Reads a VM command, separates the components, and hands them to the CodeWriter conveniently, and
	Ignores all whitespace and comments (doesn't remove them, but skips over them)

I call this the HRI or PHRI (pronounced "fry") protocol!

Routine				Arguments			Returns			Function

Constructor			Input file/stream	——				Gets ready to parse input.

hasMoreCommands		——					Boolean			Are there more commands in input?

advance				——					——				Reads next command and makes it current command.
														Only called if hasMoreCommands is true.
														There is no initial current command.

arg1				——					string			Using .split(), return splitCommand[0].
														If C_ARITHMETIC is detected, return entire command.

arg2				——					int				Returns second arg of current command.
														Only called if C_PUSH, C_POP, C_FUNCTION, or C_CALL.

commandType			——					C_ARITHMETIC,	Returns constant representing type of command.
										C_PUSH, C_POP,	C_ARITHMETIC is returned for all arithmetic and
										C_LABEL,		logical commands.
										C_GOTO, C_IF,
										C_FUNCTION,
										C_RETURN,
										C_CALL


CodeWriter API generates assembly code from parsed VM command.

Routine				Arguments			Returns			Function

Constructor			Output file/stream	——				Gets ready to write output.

writeArithmetic		command (string)	——				Writes assembly code that implements C_ARITHMETIC.

writePushPop		push/pop command,	——				Writes assembly code that implements given command.
					segment (str),
					index (int)

Close				——					——				Closes output file.

More routines will be added in Project 8!

But you can add private methods to make code more manageable.

[I've worked on project 7 from around April 15 to May 03 and there were several development gaps.]

from enum import Enum
class Shake(Enum):
	VANILLA = 7
	CHOCOLATE = 4
	COOKIES = 9
	MINT = 3

for shake in Shake:
	print(shake)





May 3rd, 2022



Unit 2.1: Program Control

everything was predetermined
	start at high-level
	break down to x = -b+sqrt(disc(a,b,c))
	step back and see abstractions

functions:
	all functions are abstractions!
	what about implementation?
	the basic language can be extended  at  will

	branching: maybe check if a==0
	compiler translates code





May 4th, 2022



Branching commands:
	goto label (that's literally @LABEL, 0;JMP)
	if-goto label (check if current command is -1, jump in that case)
	label label (add (LABEL))
Function commands:
	call function
	function function
	return

Take home lessons:
	Branching
	Functions
	Function call-and-return
	Dynamic memory management
	Stack processing
	Pointers
	Completing the VM implementation

next unit: branching!



Unit 2.2: Branching

started with arithmetic, logical, memory segment commands
now working on branching commands 

branching is easy to understand
usually, we'd just go straight down in program
branching adds all sorts of curves and twisty-turns!

low-level:
	unconditional branching
	conditional branching

pseudo-vm
	mult's naive while loop uses labels!
	we don't "have" to worry about the compiler... but I want to
	if-goto requires a push operation just before the if-goto command
		pops the top of the stack!

three branching:
	goto label
	if-goto label
	label label

	implementation:
		translate each branching command into assembly instructions that effect the specified opperation
		this is simple because the assembly language has similar branching commands!



Unit 2.3: Functions

high-level programming is just a set of basic functions, plus:
	Subroutines
	Functions
	Procedures
	Methods
	And more

where do all of these come from?
	different languages have different specifications
	we call these "functions"

how do we implement the notion of FUNCTIONS?
	a high-level program with a square root and multiplication can be simplified to abstract functions
	There are two features in VM:
		primitive operations (fixed) such as add, sub, neg
		abstract operations (extensible) such as Math.multiply, Math.sqrt, etc.
		you can try writing more!

if you want to call a function:
	push all parameters to function
	call function, execute "magic"
	result will replace parameters

primitive operators and calling functions just executes a function. 

VM code for naive mult:
	function mult 2
	push constant 0
	pop local 0
	push constant 1
	pop local 1
label LOOP
	push local 1
	push argument 1
	gt
	if-goto END
	push local 0
	push argument 0
	add
	pop local 0
	push local 1
	push constant 1
	add
	pop local 1
	goto LOOP
label END
	push local 0
	return

functions:
	function functionName nArgs, where:
		functionName is the name of the function, and
		nArgs is a positive integer of arguments.

	call functionName nArgs 2
		functionName is name of the function
		nArgs is a positive integer of arguments

	calling function: caller
	called function: callee

main view:
	after line 3: stack
				  _______
				  |		|
				  |  3  |
				  |_____|
				  |		|
				  |  8  |
				  |_____|
				  |		|
				  |  5  |
				  |_____|

	
	after line 4: stack has 3 and 40

	after line 5: stack has 43

mult view:
	stack is empty			argument has 8 and 5		local has 0 and 0

	stack has 1 and 5		argument has 8 and 5		local has 0 and 1

	stack now has 40		argument has 8 and 5		local has 40 and 6


line triple 7! What to do to make this clever "magic" happen?

for each function call, the code has to:
	pass parameters from the calling function to the called function
	determine the return address within the caller's code
	save the caller's return address, stack, and memory segments
	jump to execute the called function

think about this as an adventure: you go on a loop and have to arrive at the exact next instruction

for each return, the code has to:
	return to the caller the value computed by the called function
	recycle the memory resources used by the called function
		you MUST push a value onto the stack before you return!!
	reinstate the caller's stack and memory segments
	jump to the return address in the caller's code



Unit 2.4: Function Call and Return: Implementation Preview

How to implement call, function, and return:
	2.4 = Implementation Preview 
	2.5 = Run-time simulation
	2.6 = Detailed implementation

function execution:
	A program usually has many functions
	1-2 functions are executing at the same time usually
	Calling chain: foo>bar>sqrt>...

for each function in chain, we have to maintain the state of the function

function state is also imaginary

working stack and some segments should be:
	created when the function starts runnign,
	maintained as long as the function is executing
	recycled when the function returns

how do we maintain all of these states?
	calling pattern is LIFO (last in first out, stack)
	___ (upper hand)
	 ↑
	 |
	___ (lower hand)
	 
	 |
	 ↓

	 this VM's favorite datastructure: the stack!

Example! compute 17 * 212 or mult(17, 212)

Net effect was the functions arguments replaced by function value

funny example:
	You have a robotic Robbie cleaning rugs. It cleans the rug while you watch it.
	It is running a function as it cleans the rug; that's how it functions (haha).
	Eventually, you shout: "Hey Robbie, make me a cup of tea!"
	Robbie stops what it's doing, and runs another function making a cup of tea.
	Later: Robbie finishes making tea for you. He returns the cup to you.
	Robbie is done with the tea function, now he is going back to cleaning up.

introduction: the global stack

many pairs of caller-callee up the calling chain
your stack can only handle so much of that, and will have to save states of other functions





2022, May 5th (⅓ birthday!)


frame only contains four memory segment values even though there are 8 others. Segments:
	Local
	Argument
	This
	That
	Static
	Constant
	Pointer
	Temp

uses the same stack for both arithmetic-logical commands and behind-the-scene work!
behind-the-scene work includes saving addresses

How to compute function(x1, x2, ...)
Abstraction: call stack with arguments ➜ the value

Implementation: went over it, details later!

"Any sufficiently advanced technology is indistinguishable from magic."
——Arthur C. Clarke (1962)

next up: Run-Time Simulation



Unit 2.5: Function Call and Return: Run-time Simulation

example program: factorial

function goes into pseudo VM

realized: every time we make a new function, we make a function call!

full code for VM program:
function main 0
	push constant 3
	call factorial 1
	return

function factorial 0
	push argument 0
	push constant 1
	eq											888th line!							:D
	if-goto BASECASE

	push argument 0
	push argument 0
	push constant 1
	sub
	call factorial 1
	call mult 2

	label BASECASE
		push constant 1
		return





2022, May 6th


Note that the function calls itself once.

two-tier compilation is nice because a compiler compiles the code to about twice as many commands!
without two-tier compilation, each file would be translated to a giant jumble of assembly.

start with empty global stack when running factorial
push 3
call factorial 1 (save main frame)
jump to exectute factorial
push 3 and 1
3 ≠ 1
if-goto BASECASE (does not work)

push 3, 3, 1
subtract 1 from 3 = 2
call factorial at 2

repeat until factorial's local variable becomes 1

jump to the basecase when factorial's arg = 1. code for mult omitted...

question:
Suppose that function foo pushes two arguments and calls function bar.
After bar returns, the two argument values that were pushed before the call have disappeared.
The stack’s topmost value is the value returned by bar.
Who is responsible for removing the argument values from the stack?


☒ The code of the foo function


☐ The code of the bar function


☐ The VM implementation


☐ All answers are incorrect



Unit 2.6: Function Call and Return Implementation

arbitrary VM computes -(19 * (local 3))
calls function Bar.mult in the process, coming from class Bar

Calling function's view of contract between caller and callee:
	Before calling another function, I must push as many arguments as the function expects to get
	
	Next, I invoke the function using call functionName nArgs
	
	After the called function returns, the argument values that I pushed before the call have disappeared from the stack, and a return value that always exists appears at the top of the stack
	
	After the called function returns, all my memory segments are exactly the same as they were before the call (except that temp is undefined and some values of my static segment may have changed)


Callee's view of contract between caller and callee:
	Before I start executing, my argument segment has been initialized with the values passed by the caller

	My local variables has been allocated and initialized to zeroes

	My static segment has been set to the static segment of the VM file to which I belong
	(memory segments this, that, pointer, and temp are undefined upon entry)

	My working stack is empty

	Before returning, I must push a value onto the stack.

Note that these are basically copied from the video.





May 10th, 2022. Note: I don't know where times from May 6th to May 10th go.


VM's view of contract between caller and callee:
	create a translator!

handling call:
	calls the function, informing that nArgs arguments have been pushed onto the stack

pseudo-assembly:
	push returnAddress
	push LCL
	push ARG
	push THIS
	push THAT
	ARG = SP-5-nArgs
	LCL = SP
	goto functionName
	(returnAddress)


handling function:
	starts a function that has nVars local variables
	generate assembly that moves the return address, reinstates the call state, and then does a goto:
		foo's return address: return value in caller's code

handling return:
	the callee is running and adding to the stack...

pseudo-assembly:
	endFrame = LCL			// endFrame is temporary
	retAddr = *(endFrame-5)	// consider using R13
	*ARG = pop()			// repositions return value of the caller
	SP = ARG + 1			// repositions SP of caller
	THAT = *(endFrame - 1)	// repositions THAT of the caller
	THIS = *(endFrame - 1)	// repositions THIS of the caller
	ARG = *(endFrame - 1)	// repositions ARG of the caller
	LCL = *(endFrame - 1)	// repositions LCL of the caller
	goto retAddr			// goes to return address in the caller's code

everything above SP is recycled (kaput!)


recap:
	We showed how to generate the assembly code that, when executed, will end up building and maintaining the global stack during run-time

	This code will implement the function call and return commands and behavior

	The code is language- and platform-independent!

VM language:

☒ Arithmetic/Logical Commands - Unit 1
☒ Memory Access Commands - Unit 1
☒ Branching Commands - Unit 2
☒ Function Commands, the trickiest - Unit 2



Unit 2.7: VM Implementation on the Hack Platform

big picture: program compilation and translation
	myProg directory contains Foo.jack and Bar.jack (random names)
								  ↓
	    myProg directory is compiled into Foo.vm and Bar.vm
								  ↓
	      myProg directory is translated into myProg.asm

booting: what to do when computer is turned on? (and why is it called booting?)
	VM programming convention
		One file in any VM program is expected to be named Main.vm;
		one VM function in this file is expected to be named main

	VM implementation convention
		When the VM translator starts running, it starts executing the argument-less OS function Sys.init.
		Sys.init then calls Main.main, and enters an infinite loop

	Hardware platform convention
		Bootstrap code should be written in assembly
		SP=256
		Call Sys.init

Standard mapping of the VM on the Hack platform
	Hack RAM isn't just a jumble of registers ending with the stack (and it definitely doesn't end there!)
	It actually consists of: pointers/registers, static, stack, heap, memory mapped I/O, and unused memory

	special symbols in VM: 
		my photo here: C:\Users\Winry\Desktop\chrome_IPZNIQ51az.png

time to implement this!



Unit 2.8: VM Translator: Proposed Implementation

honk? Shimon is sitting on a chair and it's being displayed this time!
reason: unfortunately he broke his leg in a bicycle accident recently. He will sit down for this recording.
I noticed that the camera zoomed in, so he appears to be standing after he explains his leg injury.

We've implemented the basic functions

Same implementation is parser→codewriter→main

Main:
	input: fileName and directoryName
	output: fileName.asm or directoryName.asm file.

	process:
		construct a codeWriter
		if input is a vm file:
			constructs a parser to handle the input file
			marches through input, parsing lines and generating code





2022, May 11th


		if input is a directory:
			does the same for every file

	implementation note:
		extension of main program written in project 7

Parser:
	PHRI protocol! (search for a capitalized phri)

	implementation notes:
		same parser that was implemented in project 7
		if your parser doesn't handle branching/function commands, add functionality now.

CodeWriter:

Routine				Arguments				Returns			Function

Constructor			Output file/stream		——				Gets ready to write output.

writeArithmetic		command (string)		——				Implements given arithmetic command.

writePushPop		push/pop command,		——				Implements given memory access command.
					segment (str),
					index (int)

Close				——						——				Closes output file.

setFileName			fileName (string)		——				Tells class that a new file needs to be parsed.

writeInit			——						——				Writes bootstrap code that initializes VM.

writeLabel			label (string)			——				Writes a special label for the label command.

writeGoto			label (string)			——				Writes an immediate jump for the goto command.

writeIf				label (string)			——				Writes a conditional jump for the goto command.

writeFunction		functionName (string)	——				Implements the code for the function command.
					numVars (int)

writeCall			functionName (string)	——				Implements the code for the call command.
					numArgs (int)		

writeReturn			——						——				Implements the code for the return command.



Unit 2.9: Project 8: Building the VM Translator, Part II

big picture:
	objective: build a VM translator that translates the VM lanaguage to the Hack assembly language

testing:
	run generated code on target platform/CPUEmulator.bat
	if it works, you've finished the code and you can move on
	otherwise, redo the program and test with the same test scripts

Test programs:
	ProgramFlow:
		BasicLoop and FibonacciSeries

	FunctionCalls:
		SimpleFunction, NestedCall, FibonacciElement, and StaticsTest

	Testing routine:
		Load and run a VME test script on the emulator.
		This loads the respective VM file into the emulator, allowing you to experiment with the code.
		Use VM translator to translate your VM file. The result will be a similarly named HA file.
		Load and run a test vile on the CPU emulator.
		This loads your HA file, runs it, and compares to a compare file (all of the same name).

	BasicLoop is designed to test label and if-goto
	FibonacciSeries is designed to test all branching commands

	FunctionCalls tests:
	SimpleFunction is supposed to only test function and return.
	NestedCall is an intermediate test call when SimpleFunction works and FibonacciElement does not.
	FibonacciElement tests directory translation and function calling.
	StaticsTest makes sure you handle different file values properly.





June 23rd, 2022 (yeah we were working on the project for a looong time...)



Unit 3.1: The Jack Language in a nutshell

Jack is multi-purpose, Object oriented program
After learning another programming language with abstraction-implementation, OOP, and 
application design/implementation this should not be too hard.

First program: Hello World
	The classic hello world program. o/
	Whitespace



Second program: Procedural Processing
	declare variables with var

	Jack only deals with integers
	Jack arrays are not typed



Unit 3.2: Object-Based Programming

OO Programming: using a class
	Fraction API
	Users using an abstraction don't need to know anything about its implementation
	They just need the API (Application Programming Interface)

OO programming: building a class
	In Jack, a field is declared with the field keyword
	Fraction's fields are numerator and denominator, which are both integers (ints)

	2 accessors: getNumerator and getDenominator, returning numerator and denominator
	Accessors are REQUIRED for jack classes, they are not public!

	In Jack, you need a constructor for every class.
		This constructor can call methods from within the class. I've never tried that!

	Euclid developed an algorithm for GCD that I don't understand.

	this is a reference to the current object
	A constructor has to return this.

	You must dispose of yourself when you're done as a class!
	use "do Memory.deAlloc(this);"
		Used because Jack doesn't have garbage collection.

	The client usually thinks of classes as blocks.
		I don't think of blocks, though. I think of the object imagined in reality.



Unit 3.3: List Processing

A list is represented by the atom null or an atom followed by a list

lists can be initialized with syntax list.new(int, list.new(int, ...))

do something.print() is really invasive for the client!

recursive access is demonstrated by repeated disposal.



Unit 3.4: Jack Language Specification: Syntax

Syntax elements:
	Whitespace / Comments
	Keywords
	Symbols
	Constants
	Identifiers

Whitespace/Comments: Ignore them!
Keywords: Some of these keywords are implicit, used to make writing the compiler easier.
Symbols: Non-letter, non-number, non-variable-name characters.
Constants: Strings, numbers, bools, etc.
Identifiers: Names that no compiler man cares about.



Unit 3.5: Jack Language Specification: Data Types

There are several primitive types:
	Int: Non-negative 2's complement 16-bit integer.
	Boolean: True or false
	Character: Unicode Character
	Negative integers are actually expressions.

There are a couple class types:
	OS types: String, Array
	User-defined types: Fraction, List

Type conversions:
	Characters can be converted into each other.
	An object can be converted into an Array and vice versa.

Jack datatypes are pretty primitive, there are only 3 categories, and it's weakly typed!



Unit 3.6: Jack Language Specification: Classes

Classes that provide functionality:
	Math class API provides many mathematical operations (hopefully efficient!)
	Only functions, is a library! /read

	OS purpose:
		Closes gaps
		Provides efficient implementations of ADTs and functions
		Contains classes
		Similar to Java's standard class library.



Unit 3.7: Jack Language Specification: Methods

Last language specificiation unit!

Strings can be created by a loop that uses String's appendChar method
OR they can be created with syntactic sugar, with let String s = "string"

Arrays are not typed, and can hold any type.

There is no operator priority in Jack, the only way to "enforce" this is using parenthenses. I can enforce it in my compiler though.



Unit 3.8: Developing Apps using the Jack language and OS

Handling output: Text/Graphics
	There are several screen methods:
		clearScreen()
		setColor(boolean b)
		drawPixel(int x, int y)
		drawLine(int x1, int y1, int x2, int y2)
		drawRectangle(int x1, int y1, int x2, int y2)
		drawCircle(int x, int y, in r)

Handling input:
	There are several Keyboard methods:
		keyPressed()
		readChar()
		readLine(String message)
		readInt(String message)

Jack character set:
	I think I caught a typo. I don't think B should have a keycode of 55, as A is 65.

Jack OS:
	Math
		2 of these functions, multiply and divide, are unused.
	String
		Several useful methods including keycodes of backspace and keys like that.
	Array
		Dispose of and add to arrays. That's all the functionality.
	Memory
		peek, poke, allocate, and de-allocate. Very mischevious.
	Sys
		halt, error, and wait!
	Output
		Lots of nice printing functions
	Screen
		Draw methods
	Keyboard
		Allows reading.



Unit 3.9: A Sample Jack App: Square Dance

SquareGame demo!



Unit 3.10: Graphics Optimization

Graphics are usually made of sprites
See/access memory with Memory.peek/poke

Use the bitmap editor for more advanced sprites and use Memory.poke!



Unit 3.11: Perspectives

Three questions:
	Jack language weak-typing
	Inconventional "let" and "do" statements
	Why Jack is so primitive





July 7th



Unit 4.1: Syntax Analysis

We want to compile a class into machine language using two-tier compilation.
First-tier compilation language names:
	Jack - VM code
	Java - Bytecode
	C# - IEL?
Then we put all our VM code into the VM translator. We already made that.
We will write the compiler now.

This module: Syntax analyzer broken up into tokenizer and parser, producing XML code
Next module: actual code generator taking XML code, producing VM code

Why write a compiler?
	Gives knowledge of best practices and core ideas for big data management projects
	Allows you to understand compilers and understand high-level languages more
	Bonus for me: gives me perspective on why (and how!) certain OS or language functions were defined



Unit 4.2: Lexical Analysis

To the tokenizer this just looks like a stream of characters.
Tokenizing = grouping characters into tokens
Tokens are strings of characters that just have a meaning.

There are 5 types of tokens:
Keywords			class, constructor, function, method, field, statuc, var, int,
					char, boolean, void, true, false, null, this, let, do, if, else,
					while, return

Symbols				{  }  (  )  [  ]  '.'  ','  ';'  +  -  *  /  &  |  <  >  =  ~

Integer constants	a decimal number in the range 0 to 32767

String constants	' " ' a sequence of unicode characters, not including double quote or
					newline ' " '

Identifiers			a sequence of letters, digits, and underscore ('_') not starting with
					a digit.

output for code block:
if (x < 0) {
	// prints the sign
	let sign = "negative";
}

is supposed to be a bunch of XML:
	<keyword> if </keyword>
	<symbol> ( </symbol>
	<identifier> x </identifier>
	<symbol> < </symbol>
	...



Unit 4.3: Grammars

A grammar is a set of rules describing the permutations of tokens (order matters!) that can be combined to create valid language constructs, whether it makes sense or not.

Grammar of jack (subset):
	statement: ifStatement, whileStatement, letStatement (separated by | or "or"s)
	statements: statement* (0 or more appearances of a statement)
	ifStatement: 'if' '(' expression ')' '{' statement '}'
	letStatement: 'let' varName '=' expression ';'
	expression: term (op term)?
	term: varName|constant
	varName: a string not beginning with a digit
	op: '+'|'-'|'='|'>'|'<'

our brains do this, but with an ADDED feature!
	We can still understand sentences that have small discrepancies, otherwise poets wouldn't exist and some literature would be lost forever.
	Compilers don't have this effect, but I'm pretty sure that with some neural circuitry I could squeeze in one of these small effects...



Unit 4.4: Parse Trees

A parse tree is made from the tree datastructure in programming.
It is read from top to bottom.
It starts with a root and branches down to the 'leaves' or terminal/last nodes.
In this case, the leaves are the actual tokens.

In english there can be multiple interpretations per sentence, but in coding languages this is not possible.

XML can be used to describe a parse tree but it's really messy!





July 8th



Unit 4.5: Parser Logic

The parser is made of sets of:
	compile{rule, these curly brackets are not part of the function}() {
		// code for compiling the rule
	}

Parsing logic:
	Follow right-hand side of the rule, and parse the input accordingly
	If the right-hand side specifies a non-terminal 'Rule', call compileRule
	Do this recursively!

Detailed sim of parsing logic for while statement!

LL grammar can be parsed by a rescursive dsecent parser (what?) without backtracking
LL(k) parser is a parser that needs to look ahead at most k tokens to determine the rule.
Current grammar is LL(1) but English is something like LL(7)



Unit 4.6: The Jack Grammar

The entire jack grammar can be fit into one page!

Jack grammar: lexical elements
	Most of the terminal rules.

Jack grammar: program structure
	Collection of classes, compiled separately.

Jack expressions make the Jack language LL(2) instead of LL(1).
	Otherwise, Jack is just LL(1).

Expressions have complicated syntax and you need to look for tokens.



Unit 4.7: The Jack Analyzer

we use XML to prove that our parser 'understands' code
	...although technically it's just spitting it out
	By the way I'm not sure if neural networks actually make a computer 'smart'. It's just that the output is wired to make a computer 'intelligent'. It's still ju Is that true?

XML is nested like a tree




Unit 4.8: The Jack Analyzer: Proposed Implementation

The jack analyzer represents a class that will use the tokenizer to determine what the tokens are. The tokenizer will use hasMoreTokens, advance, and tokenType.

Jack tokenizer API:
	Constructor - opens input jack file and gets ready to tokenize it.
		Notes: I would just tokenize it right away! (oops, this is incorrect)
	
	hasMoreTokens - Are there more tokens in the input? Returns boolean.
	
	advance - Gets next token from input and makes it the current token.
	
	tokenType - Returns KEYWORD, SYMBOL, IDENTIFIER, INT_CONST, STRING_CONST.
		Notes: Any of these constants can be the type of the current token.

	keyWord - Returns the current token. Called if the token type is KEYWORD.

	symbol - Returns the current token. Called if the token type is SYMBOL.

	identifier - Returns the current token. Called if the token type is IDENTIFIER.

	intVal - Returns the current token. Called if the token type is INT_CONST.

	stringVal - Returns the current token without quotes. Called if the token type is STRING_CONST.

CompilationEngine design:
	For every non-terminal rule, CompilationEngine runs a compilation method for that rule.

CompilationEngine API:
	Constructor - Creates new compilation engine with the given input and output.

	compileClass - Compiles a complete class.

	compileClassVarDec - Compiles a static variable/field declaration.

	compileSubroutineDec - Compiles a complete method, function, or constructor.

	compileParameterList - Compiles a parameter list. Doesn't handle enclosing ().

	compileSubroutineBody - Compiles a subroutine's body.

	compileVarDec - Compiles a var declaration.

	compileStatements - Compiles a sequence of statements. Doesn't handle enclosing {}.

	compileExpression  - Compiles an expression.

	compileTerm - Compiles a term.

	compileExpressionList - Compiles a comma-separated list of expressions.



Unit 4.9: Project 10: Building a Syntax Analyzer

Goals:
	Implement syntax analyzer
	Use to parse all supplied jack files
	For each test file, analyzer should produce XML identical to supplied comp. file

Tools and resources:
	Test programs and compare files
	TextComparer: nand2tetris/tools
	XML file viewer: you use your own application

Implementation plan:
	Build jack tokenizer
	Build compilation engine:
		Basic version (everything but expressions)
		Complete version (everything, no exceptions)

XML anomalies:
	all code is wrapped in <tokens> tag so that it's loaded into browser well
	string constants don't have double quotes
	certain special characters are outputted with &identifier;

some files have	expressionless variations that don't make sense
however they're used to test all parsing abilities for non-expression tokens



Unit 5.1: Code Generation

learning about how to compile code is important because it gives people a deeper understanding of what takes place when they are running their code.
	Bonus: It also gives me extra thoughts when I'm bored about how to parse Java, Python, Javascript, and even HTML.

Roadmap: Jack program runs through Jack Compiler and turns into VM code
Jack Compiler: in the past, we only had the syntax analyzer with the tokenizer and the parser or the Compilation Engine. Now we need the code generator or CG.
XML is no longer relevant.

Parser is partially rewritten, Code Generator is built from the ground up.

try to simplify complicated coding tasks.
	Simplification 1: Each file is its own class and deserves its own compiler.
	Simplification 2: You only ned to compile the declaration of the class, then one subroutine at a time.

What does one see in a subroutine?
	Variables
	Expressions
	Flow of Control
	Objects
	Arrays

	We need to handle all of these. One unit is dedicated to each challenge.
	...well except for objects.

High-level languages are very advanced and complicated with lots of semantics.
VM is very simple. No classes, no subroutines, just a stream of commands.

Learn how to implement procedural code, arrays, and objects.
Techniques: Parsing, Recursive compilation, Code generation, Symbol tables, and Memory management (very lightly touched on here)

Next up: handling variables.



Unit 5.2: Handling Variables

sum = x * (1 + rate)
stream of VM code is generated after compilation.
let's only focus on variables.

to generate VM code, we need to know the virtual segments each variable is in.
handle class-level and subroutine-level variables

each variable has a name, type, kind or role and a scope.
more specifically, an identifier, an int/char/boolean/classname, a field/static/local/argument, and a class-level or subroutine-level scope.

variable properties are needed for code generation, and can be managed efficiently with a symbol table. (hey that's like in the assembler!)

sample code:
class Point {
	field int x, y;
	static int pointCount;

	method int distance(Point other) {
	var int dx, dy;
	let dx = x - other.getx();
	let dy = y - other.gety();
	return Math.sqrt((d*dx)+ (dy*dy));
	}
}

class-level variables with columns name, type, kind, and # of its kind

subroutine has this, then its vars

class-level symbol table is reset every time we compile a new class
subroutine symbol tables are reset every compiling of a subroutine call
codeWriter will not write anything during var dec. write only during var handling


general observations: vary in terms of var types, kinds, and scoping
they can be modified to handle variable compilation in other languages

Now that we know how to handle variables, we can move onto handling expressions!



Unit 5.3: Handling Expressions

infix example: a * (b + c)
prefix example: *a +bc
postfix example: a b c + *

stack language is very postfix-oriented

source code: x + g(2,y,-z) * 5
generate parse tree, then generate stack machine code.

from project 10, we get XML. now, in project 11, we need VM.
VM doesn't have operator priority. the compiler ignores this.
some students will ignore operator priority, others won't and will implement it.
both approaches are fine.

parentheses are to be respected, so the compiler will handle them. However, there is otherwise no operator priority.



Unit 5.4: Handling Flow of Control

if statements:
negate the expression, then goto L1 or L2
labels are generated by the compiler

while statements:
negate expression, if it's true execute something else, otherwise execute the statements
labels are, again, generated by the compiler

there are some complications:
	a program usually contains a lot of if and while statements.
		Solution: the compiler can generate unique labels.
	if and while statements may be nested. telescopic code!
		Solution: we already took care of it with recursive compilation.

variables + expressions + flow of control = compiler for simple procedural language!
	...but we still need to handle arrays and objects
a lot of the compiler is done in the parsing
because we already finished the previous tiers of the cake, we don't need to think about how we got it. we just move onto the next cake tier and make a great birthday party, because it's Mommy's birthday today.



Unit 5.5: Handling Objects: Low-Level Aspects

VM doesn't handle objects, as they only have virtual memory segments
it's even worse in low-level machine programs!
the challenge is to bridge the big gaps

first five entries hold stack pointer, local pointer, argument pointer, this pointer, and that pointer
there is a special place called the stack
local and argument variables are located on the stack, managed by VM translator

the heap handles object and array data
you might have many vars on the heap!
we need to use THIS and THAT, but first use pointer segment
managed by VM code

access RAM words 8000 onward
first anchor THIS
then access THIS i
this is the basic technique for accessing object and array data
first anchor using pointer



Unit 5.6: Handling Objects: Construction

the compiler doesn't care about the objects
initialize a class variable as a location on the stack.
when let statement is used, initialize p1 as location of the stack on the heap
what happens when there are multiple classes?

only update relevant symbol table when vars are handled
all we need to do is call the constructor!
the caller needs the constructor to allocate space for itself
pop base addres of the new object
what about the impact?

during compile-time, the compiler maps p1v, p2, and d on local 0, 1, and 2
only during runtime go to work do we allocate space on RAM
A constructor typically arranges creation of new objects and initializes it to an initial state, so it needs access to the object's fields
The constructor's code can access the object's data using the THIS segment!
however, we need to anchor the THIS segment with pointer
for fields and statics, make class-level symbol table update
we should find a free memory block on the RAM equal to the number of vars needed
provide alloc with a number and it will find a block of empty code of num's length. implemented in OS
align this with the base address of memory.alloc

every jack compiler returns this, so push pointer 0 and return

for code block:
"
constructor Point new(int ax,
					  int ay) {
  let x = ax;
  let y = ay;
  let pointCount = pointCount + 1;
  return this;
}
"

you get:

"
push constant 2
call Memory.alloc 1
pop pointer 0

// let x = ax; let y = ay;
push argument 0
pop this 0
push argument 1
pop this 1

// let pointCount = pointCount + 1;
push static 0
push constant 1
add
pop static 0

// return this
push pointer 0
return

"



5.7: Handling Objects: Manipulation

how to compile methods?
you need to rewrite the OO method calls in a procedural style
this is why you always need self as an argument, because you pass it in during the call!

example:
	"obj.foo(x1, x2, ..)"
	translated (approximately) into:
		"
		push obj
		push x1
		push x2
		push ...
		call foo
		"
caller's code:
"let d = p1.distance(p2);"

method and variable declarations do nothing
anchor this to correct segment

translated into:
	"
	push argument 0
	pop pointer 0
	push this 0
	push argument 0
	call Point.getx 1
	sub
	pop local 0
	// dy statement is very similar
	push local 0
	push local 0
	call Math.multiply 2
	push local 1
	push local 1
	call Math.multiply 2
	add call Math.sqrt 1
	return

	"

void methods are similar to normal ones, but they always have to return a value
the dummy value is dumped in some place. sadly it can't be dumped into constant



Unit 5.8: Handling Arrays
Confusion cleaner activated! I didn't realize you had to pass in a size argument for arrays. It makes their compilation a lot easier.

THIS and THAT are "portable" because their starting address can be moved.
set THIS and THAT with pointer 0 and pointer 1

example for THIS and THAT manipulation
VM is extremely secure! it isn't even handling the RAM most of the time.

array access is a bit difficult because if there are multiple arrays being accessed, you can get a pointer overwriting error!
instead of pointer, use temp

example:
"a[i] = b[j]"

generated code:
"
push a
push i
add

push b
push j
add

pop pointer 1
push that 0
pop temp 0

pop pointer 1
push temp 0

pop that 0

"

arr[expression₁] = expression₂: expression₂ can use pointer 1 and that 0 safely

this solution also works for ginormous expressions like a[a[i]] = a[b[a[b[j]]]]



Unit 5.9: Standard Mapping Over the Virtual Machine

why is there a question at the very beginning of the video that nobody can get to?

just focus on Jack to VM, we handled everything below VM in the past

Standard mapping:
accessing array entries:
	set pointer 1 to the entry's address(arr + i)
	then access entry by accessing this 0
When compiling a Jack method:
	the compiled VM code must set the base of the THIS segment to argument 0
When compiling constructors:
	the compiled VM code must allocate a memory block for the new object, then set the base of the segment THIS to the new object's base address
	the compiled VM code must return the object's base address to the caller
When compiling a void function:
	the compiled VM code must return the value constant 0
When compiling a subroutine call subName(arg1, arg2, ...):
	the caller (a VM function) must push the arguments onto the stack, then call the subroutine
If the called subroutine is a method:
	the caller must first push a reference to the object on which the method is supposed to operate
	next, the caller must push arg1, arg2, ... and then call the method
If the called subroutine is void:
	A void subroutine does not return a value at the Jack level.
	However, at the VM level, it must return some dummy value.
	Therefore, when compiling the Jack statement do subName, following the call the caller must pop (and ignore) the returned value

Compiling constants:
	null is mapped on the constant 0
	false is mapped on the constant 0
	true is mapped on the constant -1 or push 1 followed by neg

The basic Jack OS is implemented as a set of compiled VM class files
All OS class files must reside in the same directory as the VM files generated by the compiler
Any VM function can call any OS VM function

Multiplication and division are handled with OS functions
String constants are created using the String OS constructor
String assignments like x="cc...c" are handled using a series of calls to String.appendChar(c)
Object construction requires allocating space for the new object using the OS function Memory.alloc(size)
Object recycling is handled using the OS function Memory.deAlloc(object)



Unit 5.10: Completing the Compiler: Proposed Implementation

main focus of project: SymbolTable and VMWriter

either compile a single file name or a directory
JackTokenizer: doesn't need to be touched
SymbolTable: only two are needed.

SymbolTable API:
	Constructor - Creates a new symbol table.

	startSubroutine - Resets subroutine symbol table

	define - Defines new identifier of given name, type, and kind, and assigns it a running index. STATIC/FIELD identifiers have class scope, others have only subroutine scope. All arguments: name -> String, type -> String, kind -> STATIC, FIELD, ARG, VAR.

	VarCount - Returns num of variables of the given kind. Returns an integer. Arguments: kind -> STATIC, FIELD, ARG, VAR.

	KindOf - Returns STATIC, FIELD, ARG, VAR, NONE. Arguments: name (String)

	TypeOf - Returns a string. Arguments: name.

	IndexOf - Returns an int (index assigned to named identifier). Args: name.

Can be implemented with two seperate hash tables.
When we start compiling a new subroutine, the latter hash table can be reset.
When compiling error-free Jack code, each symbol not yet found in the symbol tables can be assumed to be either a subroutine name or a class name.

VMWriter emits code to output VM file.

VMWriter API:
	Constructor - Creates new write-only output .vm file. Args: file/stream.

	writePush - Writes "push" + segment + index. Args: segment, index. Trivial.

	writePop - Writes "pop" + segment + index. Args: segment, index. Trivial.

	writeArithmetic - writes an arithmetic command. Args: command. Trivial.

	writeLabel - writes a label command. Trivial.

	writeGoto - writes a goto command. Trivial.

	writeIf - writes an if-goto command. Trivial.

	writeCall - writes a call command. Trivial.

	writeFunction - writes a function command. Trivial.

	writeReturn - writes "return". Trivial.

	close - closes the output file. Trivial.

this is just an encapsulation.


CompilationEngine overview:
	gets input from a jack tokenizer and writes output using the VM writer

	Contract:
		Each compile routine should read from the input, advance, then emit with VMWriter
		compileXXX should only be called if XXX is the current syntactic element
		If XXX is part of an expression and has a value, emitted VM code should compute the value and leave it at the top of the VM's stack

CompilationEngine implementation notes:
	The CompilationEngine API is identical to the CompilationEngine API is the same as the one in the Syntax Analyzer!
	Start with SyntaxAnalyzer, morph it into full scale compiler

the next unit is about guidelines for this module.



Unit 5.11: Project 11

Project 11 is just for extending the syntax analyzer into a full-scale compiler
Stage 0 is syntax analyzer, stage 1 is symbol table handling
stage 2 is the actual code generation

Stage 1: the output of an identifier is just identifier. We can change that.

SymbolTable testing plan:
	Implementation: implement it then extend syntax analyzer with identifier handling above
This allows the symbol table to be unit-tested with project 10 test cases

Project 11 gives test programs (six in fact)

test evolving compiler on supplied test programs in the shown order:
	Seven
	ConvertToBin
	Square
	Average
	Pong
	ComplexArrays

use compiler to compile the progran directory


For each test program:
	1. Use compiler to compile program directory
	2. Check generated code, fix compiler and go back to test & stage 1 as needed
	3. Load directory into VM emulator
	4. Run the compiled program, inspect results
	5. If there's a problem, fix compiler and go back to stage 1

the only difference in the mindset of the testing is that the compiler is incorrect when the code breaks, not the code!

Test program: Seven
	Tests how your compiler handles class, do, return, and simple arithmetic
	output should look something like this:
		"
		function Main.main 0
		push constant 1
		push constant 2
		push constant 3
		call Math.multiply 2
		add
		call Output.printInt 1
		pop temp 0
		push constant 0
		return

		"

	you must see 7 at the top-left corner of the screen


Test program: DecToBinary
	tests how your compile handles expressions and procedural constructs

Test app: Square
	Tests constructors, methods, and expressions that include method calls

Test program: Average
	Tests how your compiler handles arrays and strings

Test app: Pong
	Tests how your compiler handles a complete object-oriented application, including the handling of objects and static variables.

Test program: ComplexArrays
	Tests how your compiler handles long, hairy array manipulation.



Unit 5.12: Perspective

Question 1: Jack is relatively simple, how to generate complex language code?
	there are few types in Jack but there are a lot in complex languages
	there is also no inheritance or global variables
Question 2: How difficult would it be to close the gaps between Java and Jack?
	actually it's quite difficult
Question 3: What does compiler optimization mean?
	it's not about making the compiler efficient. It's that VM code generation is optimized.



Unit 6.1: Operating System

plan of course: we're at the OS
we're developing the nand OS
typical OS services include tasks like mathematical operations and textual output
we must support these OS services
system oriented services include memory management, a file system, UI, multitasking, networking, security, and drivers
making an OS is a large undertaking!
8 classes in OS
math:
	abs
	multiply
	divide
	min
	max
	sqrt
memory:
	peek
	poke
	alloc
	deAlloc
screen:
	clearScreen
	setColor
	drawPixel
	drawLine
	drawRectangle
	drawCircle
output:
	moveCursor
	printChar
	printString
	printInt
	println
	backspace
keyboard:
	keyPresesd
	readChar
	readLine
	readInt
string:
	constructor
	dispose
	length
	charAt
	setCharAt
	appendChar
	eraseLasChar
	intValue
	setInt
	backSpace
	doubleQuote
	newLine
array:
	constructor
	dispose
sys:
	halt
	error
	wait

people can make a living out of making OS:
	theoreticians, making blueprints for the OS services
	implementers, using theoretician blueprints and implementing them
	we're both perspectives

take home lessons in module:
	running-time analysis
	resource allocation
	input handling
	vector graphics
	textual outputs
	type conversions
	string processing
	and lots, lots more

methodology:
	classical algorithms
	ingenious hacks
	implementation notes

we were slack about efficiency in the past. now in the OS, it's really important
you can't be inefficient. must be clever about it



Unit 6.2: Efficiency Matters

for widely used operations like math, efficiency really matters!
repetitive addition for multiply is pretty slow. runtime is O(N)

proposed algorithm: represent each number as bits. multiply it by 2
multiplier is column. add only columns where i'th bit of y is 1
runtime of this algorithm is simply the number of bits in a word
can be implemented very efficiently



Unit 6.3: Mathematical Operations

division:
	Naive implementation: repeated subtraction. O(N) runtime.
	Better implementation:
		find largest number x that can, multiplied by divisor, fits into dividend.
		find remainder, then we do the same thing. recursive algorithm
		look, we multiplied!
		runtime: O(log₂(N))
	Another better implementation:
		if (y > x) return 0
		q = divide(x, 2 * y)
		if ((x - 2 * q * y) < y)
			return 2 * q
		else
			return 2 * q + 1

		runtime O(log₂(N))
		algorithm involves only addition (wait, what?)

sqrt:
	No real naive implementation.
	Implementation: use binary search algorithm
		y = 0
		for j=n/2 - 1 ... 0 do
			if (y+2^j)² <= x then y = y + 2^j
		return y

multiplication implementation notes
	Negative numbers
		two's complement: algorithm works fine. no need to change anything.
	Overflow
		algorithm always returns correct answer modulo 2¹⁶
	Implementing (i'th bit of y)
		function boolean bit(int x, int i)
		bit shifting doesn't exist in jack
		instead, use array holds 16 values 2ⁱ
		support implementation of bit(x, i) as static class variable

division implementation notes
	Negative numbers
		divide |x| by |y| and set result's sign

	Handling y overflow
		make sure y doesn't become negative!
		if y>x or y<0 return 0

sqrt implementation notes
	Handling overflow:
		handles overflow properly, same manner as in division



Unit 6.4: Memory Access

Memory:
	☐ peek
	☐ poke
	☐ alloc
	☐ deAlloc

	focusing on peek and poke

OS uses low-level services that directly accesses ram, then builds upon these

function samples
	let x = Memory.peek(19003) // x becomes 7

	do Memory.poke(19003, -1) // RAM[19003] becomes 11...1, equivalent to -1

how to access RAM from Jack?
	Naive implementation:
		doesn't quite work. compiler tries to allocate array in heap, error made.

	Working implementation:
		static array ram, then set ram to 0 and gets access to ram

	now peek and poke are completely trivial



Unit 6.5: Heap Management

Memory:
	☒ peek
	☒ poke
	☐ alloc
	☐ deAlloc

	doing alloc and deAlloc

allocate and recycle memory for objects and arrays

in languages that have garbage collection, you shouldn't need to implement dispose

Heap management simple version:
	free = heapBase

	add numVars to free in alloc

	do nothing in deAlloc

	Doesn't work! You may run out of memory.

Heap management realistic:
	linked list for available heap segments

	alloc()
		if segment.size >= size + 2, then segment is "possible"
		search free list for either first possible or smallest possible segment
			first fit is assumed
		then, carve block of size size+2 from segment
		return base address of block's data part

	deAlloc()
		append object to end of freeList
		the more we recycle, the more freeList becomes fragmented

		defrag will smoosh some fragmented blocks together when needed


Implementation notes
	how to implement heap?
	static array heap, heap = 2048
	freeList = 2048
	let heap[0] = 0
	let heap[1] = 14335

	initial state: freeList contains one long segment
	use an array as just a set of pointers

Recap
	init:
		freeList = heapBase
		freeList.size = heapSize
		freeList.next = 0

	alloc(size):
		search freeList using best-fit or first-fit heuristics to obtain a segment with segment.size >= size + 2

		if no such segment is found, attempt defragmentation, else raise error.

		block = base address of the found space

		update freeList and the fields of block to account for the allocation

		return block

	deAlloc(object):
		append object to end of freeList



Unit 6.6: Graphics

Screen:
	☐ clearScreen
	☐ setColor
	☐ drawPixel
	☐ drawLine
	☐ drawRectangle
	☐ drawCircle

General graphical observations
	vector vs bitmap: vector scales up, bitmap is an image that doesn't scale.
		procreate uses both vector and bitmap
	bitmap stores sequence of bits, vector stores draw methods
	vector is great for being:
		stored
		transmitted
		scaled
		turned into bitmap

		reminds me of SVG

Vector graphics primitives
	drawPixel(x, y)
		we took an 8K word chunk and called it a screen memory map
		how to drawPixel(x, y):
			address = 32 * y + x/16
			value = Memory.peek[16384 + address]
			set the (x % 16)th bit of value to the current color
			do Memory.poke(address, value)
	drawLine(x₁, y₁, x₂, y₂) comes in the next video



Unit 6.7: Graphics

Screen:
	☐ clearScreen
	☐ setColor
	☒ drawPixel
	☐ drawLine
	☐ drawRectangle
	☐ drawCircle

vector graphics allow for separation of parts of figure
basic idea: image drawing implemented through drawLine operations
challenge: draw lines really, really fast

simplifying assumption: focus on lines that go north-east
in each stage, we must decide if we have to go right or up. how to decide fast?

algorithm:

a=0
b=0
diff=0
while ((a<=dx) and (b<=dy)) // there is more work to do
	drawPixel(x+a, y+b)
	if (diff<0),	{a=a+1; diff=diff+dy}
	else			{b=b+1; diff=diff-dx}

this algorithm only uses addition and subtraction


now what about drawing circles?

drawing a filled circle:
	drawCircle(x, y, r)
		for each dy=-r to r do:
			drawLine(x-sqrt(r²-dy²), y+dy, x+sqrt(r²-dy²), y+dy)

drawing an unfilled one:
	drawCircle(x, y, r)
		for each dy=-r to r do:
			drawPixel(x-sqrt(r²-dy²), y+dy)
			drawPixel(x+sqrt(r²-dy²), y+dy)

Implementation notes:
	drawPixel
		requires OS Memory class
		modulo operator
	drawLine
		modify algorithm for screen origin (0, 0)
		generalize algorithm to draw lines that go in any direction
		horizontal and vertical lines are special cases
	drawCircle
		can potentially lead to overflow
			however you can limit r to no greater than 181

remaining functions are trivial



Unit 6.8: Handling Textual Output

Graphical output is handled by Jack OS class Screen. 256 rows of 512 pixels.
Textual output is handled by Jack OS class Output. 23 rows of 64 characters.

two types of characters: printable and nonprintable.
	printable characters display a result in a color.
	nonprintable chars are not displayed with a color

Challenge: how to make 256 by 512 pixels 23 rows of 64 charactesr in low level.

Each character occupies fixed 11-pixel-high and 8-pixel-wide frame.
	This is a fixed-width font.

lots of work, but some of it is already done

special private function init map assigning bitmap for each char in char set
you also need to implement the cursor
	Must be managed as follows:
		if asked to display newline, move curser to beginning of next line
		if asked to display backspase: move the cursor one column left
		if asked to display any other char: display char, move cursor 1 right

API:
class Output {
	function void init () {}

	// moves cursor to j'th column of i'th row, erasing last character
	function void moveCursor(int i, int j) {}

	// displays c at cursor location, advance cursor to the right
	function void printChar(char c) {}

	// displays str starting at the cursor location, advances cursor appropriately
	function void printString(String str) {
		// implementation is likely simply to iterate through str and printChar
	}

	// displays i starting at cursor location, advances cursor appropriately
	function void printInt(int i) {}

	// advances cursor to next line
	function void println() {}

	// moves cursor one column back
	function void backSpace() {}
}



Unit 6.9: Input

in the middle of unused memory space and the screen, there's a single kb register
	when a key is pressed on the keyboard, kb register is set to scan code
	when no key is pressed, the keyboard register is set to 0

keyPressed:
	listens to the keyboard
	if keyboard key is pressed, return scan code. else return 0.

readChar:
	waits until keypress and release, echo key, advance, return char value
	display cursor
	while (keyPressed() = 0):
		do nothing

	c=code of current key
	while (!(keyPressed() = 0)):
		do nothing

	display c
	advance cursor

readLine:
	str = empty string
	repeat
		c = readChar()
		if (c = newLine):
			display newLine
			return str

		else if (c = backSpace):
			remove last char from str
			do Output.backspace()

		else
			str = str.append(c)

Implementation notes:
	keyPressed: use Memory.peek for keyboard register
	readChar: implement algorithm
	readLine: implement algorithm
	readInt: read digits and build integer value



Unit 6.10: String Processing

API:
	"
	class String {
		...

		// erases last character from string
		method void eraseLastChar() {}

		// returns int value of this string until first non-numeric char
		method int intValue() {}

		// sets this string to representation of given num
		method void setInt(int number) {}

		// returns newline char
		function char newLine() {}

		// returns backspace char
		function char backSpace() {}

		// returns double quote char
		function char doubleQuote() {}
	}
	
	"

usually you create var String s and var int x, then append characters to s
when s.setInt(int) is called, s = str(int)
then you can use the string's int value for manipulation

most interesting functions: string and int transformations

int to string:
	int2String(val):
		lastDigit = val % 10
		c = character representing lastDigit
		if val<10:
			return c as a string
		return int2String(val/10).append(c)

string to int:
	string2Int(str):
		val = 0
		for (i=0 ... str.length) do
			d=integer value of str[i]
			val = val * 10 + d
		return val

implementation notes
	represent string as an array

	constructor String new(int maxLength) {
		let str = Array.new(maxLength);
		let length = 0;
		return this;
	}

	length, charAt, setCharAt, appendChar, eraseLastChar are array manipulations

	intValue and setInt are string2Int and int2String.
		is this a reference to the course name, nand2tetris?

	newLine, backSpace, doubleQuote return 128, 129, 34, respectively



Unit 6.11: Array Processing

should be titled Array Representation

API is trivial: function Array new (int size) and method void dispose().

client will initialize an array, then set a certain element to a value

apparently, "Arrray.new" is a function, not a constructor.
	So what happened to Array.new? Why isn't it mentioned?
you have to implicitly use Memory.alloc.

Array.dispose is trivial, just use Memory.deAlloc



Unit 6.12: The Sys Class

the last class in the operating system!

most interesting function is init()

bootstrapping/booting: process of loading basic software after general reset

when computer is reset, execution starts with ROM[0] immediately
VM needs to do sp=256, call Sys.init
program execution starts with Main.main
Sys.init: initialize OS, then call Main.main()
Sys.halt: implemented with infinite loop
Sys.wait: implemented with a loop, machine specific
Sys.error: prints given error code in form "ERR<errorCode>", and halts



Unit 6.13: Project 12: Building the OS

the OS is just an abstraction specified by Jack OS API
as a normal user we would not bother with implementation of OS
	in nand2Tetris, we will build and realize the OS ourselves

OS implementations are stored in VME and tools. both are implemented in VM
my implementation is project 12.

suppose you want to implement existing OS with modules dependent on each other
	implement module separately and use the remaining modules to help

test process:
	put files into directory
	compile directory
	execute directory in VMEmulator

Screen, Output, String, Keyboard, Sys only have Main.jack test programs.
Memory, Array, Math have .jack, .tst, and .cmp files as well

Final test:
	make copy of directory nand2tetris/projects/11/Pong
	copy 8 compiled .vm files of your OS into directory
	execute this directory in the supplied VM emulator.
